{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, log_loss, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>147.608373</td>\n",
       "      <td>38.186345</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168761</td>\n",
       "      <td>1.098755</td>\n",
       "      <td>36.955992</td>\n",
       "      <td>8.454598</td>\n",
       "      <td>11.438066</td>\n",
       "      <td>177.243120</td>\n",
       "      <td>338.729256</td>\n",
       "      <td>2.021704</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.601749</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>51.130326</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>11.649033</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>225.632949</td>\n",
       "      <td>0.481860</td>\n",
       "      <td>20597.447822</td>\n",
       "      <td>3.723330</td>\n",
       "      <td>15.376190</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>4.634376</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>69.233685</td>\n",
       "      <td>0.080920</td>\n",
       "      <td>0.112265</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078213</td>\n",
       "      <td>110.079689</td>\n",
       "      <td>2.208138</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>236.079314</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.576302</td>\n",
       "      <td>33.875790</td>\n",
       "      <td>1.813727</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18.181860</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>1.098102</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380281</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>176.948915</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>27.117165</td>\n",
       "      <td>0.081819</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>524.327396</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.555672</td>\n",
       "      <td>38.613386</td>\n",
       "      <td>0.260989</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>194.798039</td>\n",
       "      <td>0.055053</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>13.569707</td>\n",
       "      <td>18.138496</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "0    0.001660    0.591013  147.608373   38.186345    0.000421    0.000612   \n",
       "1    1.601749    0.015052    0.035864   51.130326    0.000909    0.002397   \n",
       "2    0.098039   69.233685    0.080920    0.112265    0.000909    0.001972   \n",
       "3   18.181860    0.047325    0.018061    1.098102    0.000909    0.002397   \n",
       "4    0.012085    0.008749    0.005509  524.327396    0.000909    0.002397   \n",
       "\n",
       "    Parameter7  Parameter8  Parameter9  Parameter10  ...  Attribute2  \\\n",
       "0  2286.523413    0.035407    0.593081     1.010385  ...    0.168761   \n",
       "1  2286.523413    0.035407    0.593081     1.010385  ...   11.649033   \n",
       "2  2286.523413    0.035407    0.593081     1.010385  ...    0.078213   \n",
       "3  2286.523413    0.035407    0.593081     1.010385  ...    0.380281   \n",
       "4  2286.523413    0.035407    0.593081     1.010385  ...    1.555672   \n",
       "\n",
       "   Attribute3  Attribute4  Attribute5    Attribute6  Attribute7  Attribute8  \\\n",
       "0    1.098755   36.955992    8.454598     11.438066  177.243120  338.729256   \n",
       "1    0.066671  225.632949    0.481860  20597.447822    3.723330   15.376190   \n",
       "2  110.079689    2.208138    0.073525    236.079314    0.064196    0.576302   \n",
       "3    0.011491    0.654517    0.025872    176.948915    0.029777    0.246726   \n",
       "4   38.613386    0.260989    0.009380    194.798039    0.055053    0.014725   \n",
       "\n",
       "   Attribute9  Attribute10  Quality_label  \n",
       "0    2.021704     0.079526           Pass  \n",
       "1    0.986973     4.634376           Fail  \n",
       "2   33.875790     1.813727           Fail  \n",
       "3   27.117165     0.081819           Fail  \n",
       "4   13.569707    18.138496           Fail  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "src_train = pd.read_csv('data/train.csv')\n",
    "groupID = test['Group']\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Quality_label</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11995</td>\n",
       "      <td>765.876721</td>\n",
       "      <td>0.053836</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.125856</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>51.944717</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11996</td>\n",
       "      <td>0.071211</td>\n",
       "      <td>0.924208</td>\n",
       "      <td>284.265495</td>\n",
       "      <td>15.668770</td>\n",
       "      <td>3.095123</td>\n",
       "      <td>1.817391</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>6.783967</td>\n",
       "      <td>0.195680</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11997</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>7.829744</td>\n",
       "      <td>16.138304</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.741630</td>\n",
       "      <td>1.495371</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.073078</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11998</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.672029</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.149019</td>\n",
       "      <td>3.454681</td>\n",
       "      <td>3.262468</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>6.783967</td>\n",
       "      <td>0.027291</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11999</td>\n",
       "      <td>1.026527</td>\n",
       "      <td>0.116152</td>\n",
       "      <td>2.923321</td>\n",
       "      <td>610.091923</td>\n",
       "      <td>1.031282</td>\n",
       "      <td>0.833011</td>\n",
       "      <td>0.038483</td>\n",
       "      <td>2.931083</td>\n",
       "      <td>2.005852</td>\n",
       "      <td>0.073078</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "11995  765.876721    0.053836    0.258969    0.125856    0.000218    0.000414   \n",
       "11996    0.071211    0.924208  284.265495   15.668770    3.095123    1.817391   \n",
       "11997    0.001922    7.829744   16.138304    0.000376    0.741630    1.495371   \n",
       "11998    0.000054    0.672029    0.002134    0.149019    3.454681    3.262468   \n",
       "11999    1.026527    0.116152    2.923321  610.091923    1.031282    0.833011   \n",
       "\n",
       "        Parameter7  Parameter8  Parameter9  Parameter10  ...  Attribute3  \\\n",
       "11995  2286.523413    0.035407    0.593081    51.944717  ...         NaN   \n",
       "11996     0.600827   17.850021    6.783967     0.195680  ...         NaN   \n",
       "11997     0.600827   17.850021    0.051850     0.073078  ...         NaN   \n",
       "11998     0.600827   17.850021    6.783967     0.027291  ...         NaN   \n",
       "11999     0.038483    2.931083    2.005852     0.073078  ...         NaN   \n",
       "\n",
       "       Attribute4  Attribute5  Attribute6  Attribute7  Attribute8  Attribute9  \\\n",
       "11995         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "11996         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "11997         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "11998         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "11999         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "       Attribute10  Quality_label  Group  \n",
       "11995          NaN            NaN  119.0  \n",
       "11996          NaN            NaN  119.0  \n",
       "11997          NaN            NaN  119.0  \n",
       "11998          NaN            NaN  119.0  \n",
       "11999          NaN            NaN  119.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_map = {'Excellent': 0, 'Good': 1, 'Pass': 2, 'Fail': 3}\n",
    "train['Quality_label'] = train['Quality_label'].map(quality_map)\n",
    "\n",
    "full_data = pd.concat([train, test], ignore_index=True, sort=False)\n",
    "full_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_feat = ['Parameter{0}'.format(i) for i in range(5, 11)]\n",
    "# para_feat = ['Parameter{0}'.format(i) for i in [5,6,7,10]]\n",
    "para_feat_all = ['Parameter{0}'.format(i) for i in range(1, 11)]\n",
    "attr_feat = ['Attribute{0}'.format(i) for i in range(1, 11)]\n",
    "\n",
    "full_data[attr_feat] = np.log10(full_data[attr_feat])\n",
    "full_data[para_feat_all] = np.log10(full_data[para_feat_all])\n",
    "test_index = (full_data['Quality_label'].isnull()) | (full_data['Quality_label'] == -1)\n",
    "train = full_data[~test_index]\n",
    "test = full_data[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = ['Attribute4', 'Attribute5', 'Attribute6']\n",
    "x = train.loc[:, features].values\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['p1', 'p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf['Quality_label'] = src_train['Quality_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>Quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.406507</td>\n",
       "      <td>0.736586</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.380953</td>\n",
       "      <td>3.422652</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.265881</td>\n",
       "      <td>1.964373</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.800863</td>\n",
       "      <td>1.906743</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.248371</td>\n",
       "      <td>1.982040</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5995</td>\n",
       "      <td>-1.896014</td>\n",
       "      <td>0.796836</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5996</td>\n",
       "      <td>-0.917524</td>\n",
       "      <td>0.902687</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5997</td>\n",
       "      <td>-1.067193</td>\n",
       "      <td>0.949785</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5998</td>\n",
       "      <td>-1.854479</td>\n",
       "      <td>0.621444</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5999</td>\n",
       "      <td>-1.865641</td>\n",
       "      <td>0.313045</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            p1        p2 Quality_label\n",
       "0     1.406507  0.736586          Pass\n",
       "1     1.380953  3.422652          Fail\n",
       "2    -0.265881  1.964373          Fail\n",
       "3    -0.800863  1.906743          Fail\n",
       "4    -1.248371  1.982040          Fail\n",
       "...        ...       ...           ...\n",
       "5995 -1.896014  0.796836          Pass\n",
       "5996 -0.917524  0.902687          Pass\n",
       "5997 -1.067193  0.949785          Pass\n",
       "5998 -1.854479  0.621444          Pass\n",
       "5999 -1.865641  0.313045          Pass\n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = ['Pass', 'Good', 'Fail', 'Excellent']\n",
    "colors = ['r', 'g', 'b', 'yellow']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = principalDf['Quality_label'] == target\n",
    "    ax.scatter(principalDf.loc[indicesToKeep, 'p1']\n",
    "               , principalDf.loc[indicesToKeep, 'p2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Quality_label</th>\n",
       "      <th>Group</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-2.779860</td>\n",
       "      <td>-0.228403</td>\n",
       "      <td>2.169111</td>\n",
       "      <td>1.581908</td>\n",
       "      <td>-3.375457</td>\n",
       "      <td>-3.213225</td>\n",
       "      <td>3.359176</td>\n",
       "      <td>-1.450909</td>\n",
       "      <td>-0.226886</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927093</td>\n",
       "      <td>1.058353</td>\n",
       "      <td>2.248569</td>\n",
       "      <td>2.529853</td>\n",
       "      <td>0.305718</td>\n",
       "      <td>-1.099493</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.406507</td>\n",
       "      <td>0.736586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.204594</td>\n",
       "      <td>-1.822415</td>\n",
       "      <td>-1.445336</td>\n",
       "      <td>1.708679</td>\n",
       "      <td>-3.041347</td>\n",
       "      <td>-2.620330</td>\n",
       "      <td>3.359176</td>\n",
       "      <td>-1.450909</td>\n",
       "      <td>-0.226886</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317079</td>\n",
       "      <td>4.313813</td>\n",
       "      <td>0.570932</td>\n",
       "      <td>1.186849</td>\n",
       "      <td>-0.005695</td>\n",
       "      <td>0.665991</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.380953</td>\n",
       "      <td>3.422652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.008602</td>\n",
       "      <td>1.840317</td>\n",
       "      <td>-1.091943</td>\n",
       "      <td>-0.949754</td>\n",
       "      <td>-3.041347</td>\n",
       "      <td>-2.705029</td>\n",
       "      <td>3.359176</td>\n",
       "      <td>-1.450909</td>\n",
       "      <td>-0.226886</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.133567</td>\n",
       "      <td>2.373058</td>\n",
       "      <td>-1.192495</td>\n",
       "      <td>-0.239350</td>\n",
       "      <td>1.529889</td>\n",
       "      <td>0.258572</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.265881</td>\n",
       "      <td>1.964373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.259638</td>\n",
       "      <td>-1.324909</td>\n",
       "      <td>-1.743252</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>-3.041347</td>\n",
       "      <td>-2.620330</td>\n",
       "      <td>3.359176</td>\n",
       "      <td>-1.450909</td>\n",
       "      <td>-0.226886</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.587172</td>\n",
       "      <td>2.247848</td>\n",
       "      <td>-1.526116</td>\n",
       "      <td>-0.607785</td>\n",
       "      <td>1.433244</td>\n",
       "      <td>-1.087147</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.800863</td>\n",
       "      <td>1.906743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.917741</td>\n",
       "      <td>-2.058059</td>\n",
       "      <td>-2.258966</td>\n",
       "      <td>2.719603</td>\n",
       "      <td>-3.041347</td>\n",
       "      <td>-2.620330</td>\n",
       "      <td>3.359176</td>\n",
       "      <td>-1.450909</td>\n",
       "      <td>-0.226886</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.027816</td>\n",
       "      <td>2.289585</td>\n",
       "      <td>-1.259219</td>\n",
       "      <td>-1.831939</td>\n",
       "      <td>1.132570</td>\n",
       "      <td>1.258601</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.248371</td>\n",
       "      <td>1.982040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "0   -2.779860   -0.228403    2.169111    1.581908   -3.375457   -3.213225   \n",
       "1    0.204594   -1.822415   -1.445336    1.708679   -3.041347   -2.620330   \n",
       "2   -1.008602    1.840317   -1.091943   -0.949754   -3.041347   -2.705029   \n",
       "3    1.259638   -1.324909   -1.743252    0.040643   -3.041347   -2.620330   \n",
       "4   -1.917741   -2.058059   -2.258966    2.719603   -3.041347   -2.620330   \n",
       "\n",
       "   Parameter7  Parameter8  Parameter9  Parameter10  ...  Attribute5  \\\n",
       "0    3.359176   -1.450909   -0.226886     0.004487  ...    0.927093   \n",
       "1    3.359176   -1.450909   -0.226886     0.004487  ...   -0.317079   \n",
       "2    3.359176   -1.450909   -0.226886     0.004487  ...   -1.133567   \n",
       "3    3.359176   -1.450909   -0.226886     0.004487  ...   -1.587172   \n",
       "4    3.359176   -1.450909   -0.226886     0.004487  ...   -2.027816   \n",
       "\n",
       "   Attribute6  Attribute7  Attribute8  Attribute9  Attribute10  Quality_label  \\\n",
       "0    1.058353    2.248569    2.529853    0.305718    -1.099493            2.0   \n",
       "1    4.313813    0.570932    1.186849   -0.005695     0.665991            3.0   \n",
       "2    2.373058   -1.192495   -0.239350    1.529889     0.258572            3.0   \n",
       "3    2.247848   -1.526116   -0.607785    1.433244    -1.087147            3.0   \n",
       "4    2.289585   -1.259219   -1.831939    1.132570     1.258601            3.0   \n",
       "\n",
       "   Group        p1        p2  \n",
       "0    NaN  1.406507  0.736586  \n",
       "1    NaN  1.380953  3.422652  \n",
       "2    NaN -0.265881  1.964373  \n",
       "3    NaN -0.800863  1.906743  \n",
       "4    NaN -1.248371  1.982040  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['p1'] = principalDf['p1']\n",
    "train['p2'] = principalDf['p2']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************CTB 1*************\n",
    "\n",
    "def my_scorer(y_true, y_predicted, X_test):\n",
    "    loss_train = np.sum((y_true - y_predicted)**2, axis=0) / (X_test.shape[0])  #RMSE\n",
    "    loss_train = loss_train **0.5\n",
    "    score = 1/(1+loss_train)\n",
    "    return score\n",
    "\n",
    "def model(features, test_features, label, encoding='ohe', n_folds = 4):\n",
    "\n",
    "    test_group = test_features['Group']\n",
    "    \n",
    "    labels = features[label]\n",
    "\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = [label])\n",
    "    test_features = test_features.drop(columns = ['Group'])\n",
    "\n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "\n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "\n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "\n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "\n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "\n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "\n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "\n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "\n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "\n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    train_predictions = np.zeros(features.shape[0])\n",
    "\n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "\n",
    "    # Lists for recording validation and training scores\n",
    "    #valid_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "\n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "\n",
    "        model = ctb.CatBoostRegressor(iterations=1500, depth=6, learning_rate=0.01, loss_function='RMSE',\n",
    "                                      logging_level='Verbose')\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels,\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  early_stopping_rounds = 300, verbose = 5000)\n",
    "\n",
    "        # Record the best iteration\n",
    "#         best_iteration = model.best_iteration\n",
    "#         print('BEST_ITER:', best_iteration)\n",
    "\n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "\n",
    "        # Make predictions\n",
    "        test_predictions += model.predict(test_features)/ k_fold.n_splits\n",
    "        train_predictions += model.predict(features)/ k_fold.n_splits\n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold      = model.predict(valid_features)/ k_fold.n_splits\n",
    "\n",
    "        # Record the best score\n",
    "        train_score =  my_scorer(valid_labels,out_of_fold,valid_features)\n",
    "\n",
    "        # valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "\n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'Group': test_group, label: test_predictions})\n",
    "    train_sub = pd.DataFrame({label: train_predictions})\n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "\n",
    "    # Overall validation score\n",
    "    #valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "\n",
    "    # Add the overall scores to the metrics\n",
    "    #valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "\n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "\n",
    "    # Dataframe of validation scores\n",
    "    metric = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            })\n",
    "\n",
    "    return submission, feature_importances, metric, train_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 2.1939324\ttest: 2.2214718\ttest1: 2.1939324\tbest: 2.1939324 (0)\ttotal: 4.86ms\tremaining: 7.29s\n",
      "1499:\tlearn: 2.1167584\ttest: 2.2436739\ttest1: 2.1167584\tbest: 2.1167584 (1499)\ttotal: 3.59s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.116758373\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 2.2196542\ttest: 2.1424758\ttest1: 2.2196542\tbest: 2.2196542 (0)\ttotal: 17ms\tremaining: 25.5s\n",
      "1499:\tlearn: 2.1464007\ttest: 2.1470554\ttest1: 2.1464007\tbest: 2.1464007 (1499)\ttotal: 4.07s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.146400706\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 2.1937905\ttest: 2.2212563\ttest1: 2.1937905\tbest: 2.1937905 (0)\ttotal: 5.57ms\tremaining: 8.35s\n",
      "1499:\tlearn: 2.1099508\ttest: 2.2475128\ttest1: 2.1099508\tbest: 2.1099508 (1499)\ttotal: 5.78s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.109950815\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 2.1946849\ttest: 2.2191681\ttest1: 2.1946849\tbest: 2.1946849 (0)\ttotal: 8.49ms\tremaining: 12.7s\n",
      "1499:\tlearn: 2.1153550\ttest: 2.2411419\ttest1: 2.1153550\tbest: 2.1153550 (1499)\ttotal: 5.78s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.11535505\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 2.2884644\ttest: 2.2337734\ttest1: 2.2884644\tbest: 2.2884644 (0)\ttotal: 8.57ms\tremaining: 12.9s\n",
      "1499:\tlearn: 2.2049048\ttest: 2.2565211\ttest1: 2.2049048\tbest: 2.2049048 (1499)\ttotal: 7.41s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.204904796\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 2.2738906\ttest: 2.2780294\ttest1: 2.2738906\tbest: 2.2738906 (0)\ttotal: 5.77ms\tremaining: 8.65s\n",
      "1499:\tlearn: 2.1957101\ttest: 2.2873993\ttest1: 2.1957101\tbest: 2.1957101 (1499)\ttotal: 6.33s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.195710089\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 2.2646377\ttest: 2.3058421\ttest1: 2.2646377\tbest: 2.2646377 (0)\ttotal: 5.26ms\tremaining: 7.89s\n",
      "1499:\tlearn: 2.1752097\ttest: 2.3343399\ttest1: 2.1752097\tbest: 2.1752097 (1499)\ttotal: 7.73s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.175209744\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 2.2724532\ttest: 2.2821453\ttest1: 2.2724532\tbest: 2.2724532 (0)\ttotal: 5.15ms\tremaining: 7.72s\n",
      "1499:\tlearn: 2.1922582\ttest: 2.3046829\ttest1: 2.1922582\tbest: 2.1922582 (1499)\ttotal: 6.64s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.192258155\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute2 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.5147609\ttest: 1.5108513\ttest1: 1.5147609\tbest: 1.5147609 (0)\ttotal: 3.94ms\tremaining: 5.9s\n",
      "1499:\tlearn: 1.4468531\ttest: 1.5158942\ttest1: 1.4468531\tbest: 1.4468531 (1499)\ttotal: 7.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.446853057\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.5059226\ttest: 1.5370490\ttest1: 1.5059226\tbest: 1.5059226 (0)\ttotal: 5.64ms\tremaining: 8.45s\n",
      "1499:\tlearn: 1.4403800\ttest: 1.5407022\ttest1: 1.4403800\tbest: 1.4403800 (1499)\ttotal: 8.29s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.440379956\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.5178758\ttest: 1.5015822\ttest1: 1.5178758\tbest: 1.5178758 (0)\ttotal: 9.25ms\tremaining: 13.9s\n",
      "1499:\tlearn: 1.4508663\ttest: 1.5075799\ttest1: 1.4508663\tbest: 1.4508663 (1499)\ttotal: 5.68s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.450866253\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.5163307\ttest: 1.5059925\ttest1: 1.5163307\tbest: 1.5163307 (0)\ttotal: 8.18ms\tremaining: 12.3s\n",
      "1499:\tlearn: 1.4495144\ttest: 1.5164849\ttest1: 1.4495144\tbest: 1.4495144 (1499)\ttotal: 5.33s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.449514438\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute3 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.3037891\ttest: 1.3311568\ttest1: 1.3037891\tbest: 1.3037891 (0)\ttotal: 3.91ms\tremaining: 5.86s\n",
      "1499:\tlearn: 0.8360705\ttest: 0.9281445\ttest1: 0.8360705\tbest: 0.8360705 (1499)\ttotal: 5.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8360704661\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3099760\ttest: 1.3118445\ttest1: 1.3099760\tbest: 1.3099760 (0)\ttotal: 3.18ms\tremaining: 4.77s\n",
      "1499:\tlearn: 0.8373252\ttest: 0.9307769\ttest1: 0.8373252\tbest: 0.8373252 (1499)\ttotal: 4.67s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8373251854\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3122116\ttest: 1.3065444\ttest1: 1.3122116\tbest: 1.3122116 (0)\ttotal: 7.74ms\tremaining: 11.6s\n",
      "1499:\tlearn: 0.8456671\ttest: 0.8813139\ttest1: 0.8456671\tbest: 0.8456671 (1499)\ttotal: 4.85s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8456670789\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3162952\ttest: 1.2938542\ttest1: 1.3162952\tbest: 1.3162952 (0)\ttotal: 8.26ms\tremaining: 12.4s\n",
      "1499:\tlearn: 0.8511493\ttest: 0.8802529\ttest1: 0.8511493\tbest: 0.8511493 (1499)\ttotal: 4.38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8511492928\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute4 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.3000477\ttest: 1.3236173\ttest1: 1.3000477\tbest: 1.3000477 (0)\ttotal: 3.21ms\tremaining: 4.82s\n",
      "1499:\tlearn: 0.7273883\ttest: 0.8323957\ttest1: 0.7273883\tbest: 0.7273883 (1499)\ttotal: 4.42s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7273882837\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3099571\ttest: 1.2951142\ttest1: 1.3099571\tbest: 1.3099571 (0)\ttotal: 3.44ms\tremaining: 5.16s\n",
      "1499:\tlearn: 0.7283124\ttest: 0.8238798\ttest1: 0.7283124\tbest: 0.7283124 (1499)\ttotal: 4.52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7283123676\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3033242\ttest: 1.3147463\ttest1: 1.3033242\tbest: 1.3033242 (0)\ttotal: 4.13ms\tremaining: 6.18s\n",
      "1499:\tlearn: 0.7347677\ttest: 0.7743248\ttest1: 0.7347677\tbest: 0.7347677 (1499)\ttotal: 4.68s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7347676905\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3107275\ttest: 1.2918506\ttest1: 1.3107275\tbest: 1.3107275 (0)\ttotal: 4.21ms\tremaining: 6.31s\n",
      "1499:\tlearn: 0.7411463\ttest: 0.7677329\ttest1: 0.7411463\tbest: 0.7411463 (1499)\ttotal: 5.41s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7411463307\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute5 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.3211319\ttest: 1.3470189\ttest1: 1.3211319\tbest: 1.3211319 (0)\ttotal: 3.97ms\tremaining: 5.95s\n",
      "1499:\tlearn: 0.8081311\ttest: 0.8668569\ttest1: 0.8081311\tbest: 0.8081311 (1499)\ttotal: 6.57s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8081310968\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3205219\ttest: 1.3488870\ttest1: 1.3205219\tbest: 1.3205219 (0)\ttotal: 16.5ms\tremaining: 24.8s\n",
      "1499:\tlearn: 0.8121660\ttest: 0.8650853\ttest1: 0.8121660\tbest: 0.8121660 (1499)\ttotal: 8.69s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8121659978\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3341658\ttest: 1.3076818\ttest1: 1.3341658\tbest: 1.3341658 (0)\ttotal: 22ms\tremaining: 33s\n",
      "1499:\tlearn: 0.8121564\ttest: 0.8623284\ttest1: 0.8121564\tbest: 0.8121564 (1499)\ttotal: 6.04s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8121563938\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3344264\ttest: 1.3068881\ttest1: 1.3344264\tbest: 1.3344264 (0)\ttotal: 4.68ms\tremaining: 7.01s\n",
      "1499:\tlearn: 0.8070313\ttest: 0.8708693\ttest1: 0.8070313\tbest: 0.8070313 (1499)\ttotal: 6.56s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8070312758\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute6 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.3057269\ttest: 1.3343884\ttest1: 1.3057269\tbest: 1.3057269 (0)\ttotal: 3.13ms\tremaining: 4.7s\n",
      "1499:\tlearn: 1.0920595\ttest: 1.2320691\ttest1: 1.0920595\tbest: 1.0920595 (1499)\ttotal: 5.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.092059533\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3171583\ttest: 1.3006753\ttest1: 1.3171583\tbest: 1.3171583 (0)\ttotal: 3.34ms\tremaining: 5.01s\n",
      "1499:\tlearn: 1.1122864\ttest: 1.1675612\ttest1: 1.1122864\tbest: 1.1122864 (1499)\ttotal: 6.75s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.112286432\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3090875\ttest: 1.3249787\ttest1: 1.3090875\tbest: 1.3090875 (0)\ttotal: 14.9ms\tremaining: 22.4s\n",
      "1499:\tlearn: 1.1015427\ttest: 1.1897493\ttest1: 1.1015427\tbest: 1.1015427 (1499)\ttotal: 6.35s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.101542708\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3197845\ttest: 1.2921471\ttest1: 1.3197845\tbest: 1.3197845 (0)\ttotal: 4.28ms\tremaining: 6.42s\n",
      "1499:\tlearn: 1.1098249\ttest: 1.1654726\ttest1: 1.1098249\tbest: 1.1098249 (1499)\ttotal: 5.27s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.10982492\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute7 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.3086237\ttest: 1.3267107\ttest1: 1.3086237\tbest: 1.3086237 (0)\ttotal: 3.25ms\tremaining: 4.88s\n",
      "1499:\tlearn: 1.0840021\ttest: 1.2233020\ttest1: 1.0840021\tbest: 1.0840021 (1499)\ttotal: 5.16s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.084002075\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3117137\ttest: 1.3180250\ttest1: 1.3117137\tbest: 1.3117137 (0)\ttotal: 4.54ms\tremaining: 6.81s\n",
      "1499:\tlearn: 1.1014180\ttest: 1.1816658\ttest1: 1.1014180\tbest: 1.1014180 (1499)\ttotal: 5.34s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.101418036\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3183189\ttest: 1.2988907\ttest1: 1.3183189\tbest: 1.3183189 (0)\ttotal: 7.51ms\tremaining: 11.3s\n",
      "1499:\tlearn: 1.0913487\ttest: 1.1533888\ttest1: 1.0913487\tbest: 1.0913487 (1499)\ttotal: 6.18s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.091348688\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3144477\ttest: 1.3102424\ttest1: 1.3144477\tbest: 1.3144477 (0)\ttotal: 9.33ms\tremaining: 14s\n",
      "1499:\tlearn: 1.0899977\ttest: 1.1745771\ttest1: 1.0899977\tbest: 1.0899977 (1499)\ttotal: 5.02s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.089997742\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute8 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.2876077\ttest: 1.3376118\ttest1: 1.2876077\tbest: 1.2876077 (0)\ttotal: 2.72ms\tremaining: 4.07s\n",
      "1499:\tlearn: 1.0802685\ttest: 1.2231814\ttest1: 1.0802685\tbest: 1.0802685 (1499)\ttotal: 6.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.080268521\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.2990366\ttest: 1.3055237\ttest1: 1.2990366\tbest: 1.2990366 (0)\ttotal: 9.89ms\tremaining: 14.8s\n",
      "1499:\tlearn: 1.0992279\ttest: 1.1430190\ttest1: 1.0992279\tbest: 1.0992279 (1499)\ttotal: 5.72s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.099227927\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3089536\ttest: 1.2743230\ttest1: 1.3089536\tbest: 1.3089536 (0)\ttotal: 3.14ms\tremaining: 4.71s\n",
      "1499:\tlearn: 1.0942268\ttest: 1.1438091\ttest1: 1.0942268\tbest: 1.0942268 (1499)\ttotal: 5.18s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.094226794\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3053534\ttest: 1.2854246\ttest1: 1.3053534\tbest: 1.3053534 (0)\ttotal: 3.67ms\tremaining: 5.5s\n",
      "1499:\tlearn: 1.0963373\ttest: 1.1479879\ttest1: 1.0963373\tbest: 1.0963373 (1499)\ttotal: 4.96s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.096337284\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute9 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.2939430\ttest: 1.3121365\ttest1: 1.2939430\tbest: 1.2939430 (0)\ttotal: 10.3ms\tremaining: 15.4s\n",
      "1499:\tlearn: 1.0823987\ttest: 1.2131883\ttest1: 1.0823987\tbest: 1.0823987 (1499)\ttotal: 5.47s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.082398652\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.2843913\ttest: 1.3397301\ttest1: 1.2843913\tbest: 1.2843913 (0)\ttotal: 3.85ms\tremaining: 5.78s\n",
      "1499:\tlearn: 1.0918984\ttest: 1.1926843\ttest1: 1.0918984\tbest: 1.0918984 (1499)\ttotal: 5.21s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.091898381\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3224088\ttest: 1.2232990\ttest1: 1.3224088\tbest: 1.3224088 (0)\ttotal: 3.23ms\tremaining: 4.84s\n",
      "1499:\tlearn: 1.1030321\ttest: 1.1163942\ttest1: 1.1030321\tbest: 1.1030321 (1499)\ttotal: 5.54s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.103032083\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.2922738\ttest: 1.3171632\ttest1: 1.2922738\tbest: 1.2922738 (0)\ttotal: 9.95ms\tremaining: 14.9s\n",
      "1499:\tlearn: 1.0901666\ttest: 1.1725101\ttest1: 1.0901666\tbest: 1.0901666 (1499)\ttotal: 4.72s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.090166603\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of Attribute10 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.3267380\ttest: 1.3554231\ttest1: 1.3267380\tbest: 1.3267380 (0)\ttotal: 4.21ms\tremaining: 6.31s\n",
      "1499:\tlearn: 0.8086970\ttest: 0.9122013\ttest1: 0.8086970\tbest: 0.8086970 (1499)\ttotal: 5.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8086970318\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3358666\ttest: 1.3287808\ttest1: 1.3358666\tbest: 1.3358666 (0)\ttotal: 6.45ms\tremaining: 9.67s\n",
      "1499:\tlearn: 0.8053971\ttest: 0.9130620\ttest1: 0.8053971\tbest: 0.8053971 (1499)\ttotal: 7.33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8053970704\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3333484\ttest: 1.3369272\ttest1: 1.3333484\tbest: 1.3333484 (0)\ttotal: 3.23ms\tremaining: 4.85s\n",
      "1499:\tlearn: 0.8201445\ttest: 0.8539517\ttest1: 0.8201445\tbest: 0.8201445 (1499)\ttotal: 5.26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.820144512\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.3398042\ttest: 1.3157710\ttest1: 1.3398042\tbest: 1.3398042 (0)\ttotal: 2.99ms\tremaining: 4.48s\n",
      "1499:\tlearn: 0.8251785\ttest: 0.8506562\ttest1: 0.8251785\tbest: 0.8251785 (1499)\ttotal: 5.27s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8251784752\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of p1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "0:\tlearn: 1.0841289\ttest: 1.1059824\ttest1: 1.0841289\tbest: 1.0841289 (0)\ttotal: 4.05ms\tremaining: 6.08s\n",
      "1499:\tlearn: 0.6484317\ttest: 0.6963754\ttest1: 0.6484317\tbest: 0.6484317 (1499)\ttotal: 5.24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6484316749\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.0850083\ttest: 1.1036440\ttest1: 1.0850083\tbest: 1.0850083 (0)\ttotal: 9.58ms\tremaining: 14.4s\n",
      "1499:\tlearn: 0.6519669\ttest: 0.6898747\ttest1: 0.6519669\tbest: 0.6519669 (1499)\ttotal: 5.08s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6519669285\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.0944065\ttest: 1.0747510\ttest1: 1.0944065\tbest: 1.0944065 (0)\ttotal: 6.74ms\tremaining: 10.1s\n",
      "1499:\tlearn: 0.6514124\ttest: 0.6916680\ttest1: 0.6514124\tbest: 0.6514124 (1499)\ttotal: 5.49s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6514123819\n",
      "bestIteration = 1499\n",
      "\n",
      "0:\tlearn: 1.0945850\ttest: 1.0741506\ttest1: 1.0945850\tbest: 1.0945850 (0)\ttotal: 3.28ms\tremaining: 4.91s\n",
      "1499:\tlearn: 0.6456718\ttest: 0.6977675\ttest1: 0.6456718\tbest: 0.6456718 (1499)\ttotal: 5.02s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6456717919\n",
      "bestIteration = 1499\n",
      "\n",
      "\n",
      "Prediction of p2 is done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in range(4, 7):\n",
    "for y in ['Attribute{0}'.format(i) for i in range(1, 11)] + ['p1', 'p2']:\n",
    "#     feat = ['Parameter{0}'.format(i) for i in range(1, 11)] + ['p1', 'p2']\n",
    "#     y = 'Attribute{0}'.format(i)\n",
    "    X_train = train[para_feat + [y]]\n",
    "    X_test = test[para_feat + ['Group']]\n",
    "\n",
    "    submission, fi, metric, train_sub = model(X_train, X_test, y)\n",
    "    train['ctb1_'+y] = train_sub[y]\n",
    "    test['ctb1_'+y] = submission[y]\n",
    "    print('\\nPrediction of', y, 'is done!\\n')\n",
    "    \n",
    "train.to_csv('final_data/ctb1_train.csv', index=False)\n",
    "test.to_csv('final_data/ctb1_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************XGB 1*************\n",
    "\n",
    "def my_scorer(y_true, y_predicted, X_test):\n",
    "    loss_train = np.sum((y_true - y_predicted)**2, axis=0) / (X_test.shape[0])  #RMSE\n",
    "    loss_train = loss_train **0.5\n",
    "    score = 1/(1+loss_train)\n",
    "    return score\n",
    "\n",
    "def model(features, test_features, label, encoding='ohe', n_folds = 4):\n",
    "\n",
    "    test_group = test_features['Group']\n",
    "    \n",
    "    labels = features[label]\n",
    "\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = [label])\n",
    "    test_features = test_features.drop(columns = ['Group'])\n",
    "\n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "\n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "\n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "\n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "\n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "\n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "\n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "\n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "\n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "\n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    train_predictions = np.zeros(features.shape[0])\n",
    "\n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "\n",
    "    # Lists for recording validation and training scores\n",
    "    #valid_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "\n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "\n",
    "        # Create the model\n",
    "        model = xgb.XGBRegressor(objective = 'reg:linear',n_estimators=2000, min_child_weight=1, num_leaves=20,\n",
    "                                   learning_rate = 0.01, max_depth=6, n_jobs=20,\n",
    "                                   subsample = 0.6, colsample_bytree = 0.4, colsample_bylevel = 1)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels,\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  early_stopping_rounds = 300, verbose = 5000)\n",
    "\n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration\n",
    "        print('BEST_ITER:', best_iteration)\n",
    "\n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "\n",
    "        # Make predictions\n",
    "        test_predictions += model.predict(test_features)/ k_fold.n_splits\n",
    "        train_predictions += model.predict(features)/ k_fold.n_splits\n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold      = model.predict(valid_features)/ k_fold.n_splits\n",
    "\n",
    "        # Record the best score\n",
    "        train_score =  my_scorer(valid_labels,out_of_fold,valid_features)\n",
    "\n",
    "        # valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "\n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'Group': test_group, label: test_predictions})\n",
    "    train_sub = pd.DataFrame({label: train_predictions})\n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "\n",
    "    # Overall validation score\n",
    "    #valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "\n",
    "    # Add the overall scores to the metrics\n",
    "    #valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "\n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "\n",
    "    # Dataframe of validation scores\n",
    "    metric = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            })\n",
    "\n",
    "    return submission, feature_importances, metric, train_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:26:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.25744\tvalidation_1-rmse:2.26044\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.32625\tvalidation_1-rmse:1.99836\n",
      "BEST_ITER: 1999\n",
      "[15:26:17] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.20392\tvalidation_1-rmse:2.27802\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.18496\tvalidation_1-rmse:2.04197\n",
      "BEST_ITER: 1999\n",
      "[15:26:29] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.28475\tvalidation_1-rmse:2.25128\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.29678\tvalidation_1-rmse:2.00965\n",
      "BEST_ITER: 1999\n",
      "[15:26:41] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.29263\tvalidation_1-rmse:2.24859\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.30595\tvalidation_1-rmse:1.99991\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:26:56] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.2839\tvalidation_1-rmse:2.34072\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.31094\tvalidation_1-rmse:2.08387\n",
      "BEST_ITER: 1998\n",
      "[15:27:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.33414\tvalidation_1-rmse:2.3241\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.36229\tvalidation_1-rmse:2.07127\n",
      "BEST_ITER: 1999\n",
      "[15:27:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.34953\tvalidation_1-rmse:2.31888\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.37917\tvalidation_1-rmse:2.06058\n",
      "BEST_ITER: 1999\n",
      "[15:27:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:2.3392\tvalidation_1-rmse:2.32258\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:2.37321\tvalidation_1-rmse:2.06969\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute2 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:27:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.58882\tvalidation_1-rmse:1.5986\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.53496\tvalidation_1-rmse:1.37785\n",
      "BEST_ITER: 1999\n",
      "[15:28:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.62387\tvalidation_1-rmse:1.58696\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.57553\tvalidation_1-rmse:1.36262\n",
      "BEST_ITER: 1999\n",
      "[15:28:16] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.59157\tvalidation_1-rmse:1.59778\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.52219\tvalidation_1-rmse:1.37894\n",
      "BEST_ITER: 1999\n",
      "[15:28:30] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.58082\tvalidation_1-rmse:1.60121\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.55469\tvalidation_1-rmse:1.37049\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute3 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:28:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.40773\tvalidation_1-rmse:1.39564\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.944057\tvalidation_1-rmse:0.770666\n",
      "BEST_ITER: 1999\n",
      "[15:28:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.39482\tvalidation_1-rmse:1.39986\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.937245\tvalidation_1-rmse:0.763329\n",
      "BEST_ITER: 1999\n",
      "[15:29:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.40959\tvalidation_1-rmse:1.39537\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.887487\tvalidation_1-rmse:0.780863\n",
      "BEST_ITER: 1999\n",
      "[15:29:25] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.38349\tvalidation_1-rmse:1.40397\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.884787\tvalidation_1-rmse:0.778722\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute4 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:29:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.3978\tvalidation_1-rmse:1.39602\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.854754\tvalidation_1-rmse:0.675804\n",
      "BEST_ITER: 1999\n",
      "[15:29:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.3891\tvalidation_1-rmse:1.39932\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.839405\tvalidation_1-rmse:0.672113\n",
      "BEST_ITER: 1999\n",
      "[15:30:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.41859\tvalidation_1-rmse:1.38956\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.796721\tvalidation_1-rmse:0.688571\n",
      "BEST_ITER: 1999\n",
      "[15:30:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.38186\tvalidation_1-rmse:1.40202\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.775397\tvalidation_1-rmse:0.691477\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute5 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:30:33] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.4381\tvalidation_1-rmse:1.4011\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.882241\tvalidation_1-rmse:0.740912\n",
      "BEST_ITER: 1999\n",
      "[15:30:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.41842\tvalidation_1-rmse:1.40766\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.869227\tvalidation_1-rmse:0.749991\n",
      "BEST_ITER: 1999\n",
      "[15:31:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.39253\tvalidation_1-rmse:1.41627\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.864001\tvalidation_1-rmse:0.745383\n",
      "BEST_ITER: 1999\n",
      "[15:31:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.39218\tvalidation_1-rmse:1.41602\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.867877\tvalidation_1-rmse:0.743052\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute6 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:31:29] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.41983\tvalidation_1-rmse:1.39953\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.2536\tvalidation_1-rmse:1.03524\n",
      "BEST_ITER: 1999\n",
      "[15:31:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.40055\tvalidation_1-rmse:1.40633\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.20915\tvalidation_1-rmse:1.0408\n",
      "BEST_ITER: 1999\n",
      "[15:31:57] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.41248\tvalidation_1-rmse:1.40225\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.22409\tvalidation_1-rmse:1.03623\n",
      "BEST_ITER: 1999\n",
      "[15:32:11] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.38699\tvalidation_1-rmse:1.41071\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.19456\tvalidation_1-rmse:1.04297\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute7 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:32:27] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.40721\tvalidation_1-rmse:1.40262\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.25378\tvalidation_1-rmse:1.01879\n",
      "BEST_ITER: 1999\n",
      "[15:32:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.41221\tvalidation_1-rmse:1.40129\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.21734\tvalidation_1-rmse:1.02205\n",
      "BEST_ITER: 1999\n",
      "[15:32:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.38911\tvalidation_1-rmse:1.40873\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.17818\tvalidation_1-rmse:1.03476\n",
      "BEST_ITER: 1999\n",
      "[15:33:07] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.40799\tvalidation_1-rmse:1.4025\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.20093\tvalidation_1-rmse:1.02502\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute8 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:33:19] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.40124\tvalidation_1-rmse:1.37475\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.23738\tvalidation_1-rmse:1.00103\n",
      "BEST_ITER: 1999\n",
      "[15:33:30] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.37304\tvalidation_1-rmse:1.38395\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.18063\tvalidation_1-rmse:1.01368\n",
      "BEST_ITER: 1999\n",
      "[15:33:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.37055\tvalidation_1-rmse:1.38521\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.17264\tvalidation_1-rmse:1.023\n",
      "BEST_ITER: 1999\n",
      "[15:34:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.38085\tvalidation_1-rmse:1.38135\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.15988\tvalidation_1-rmse:1.01842\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute9 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:34:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.38224\tvalidation_1-rmse:1.3839\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.22899\tvalidation_1-rmse:1.00967\n",
      "BEST_ITER: 1999\n",
      "[15:34:29] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.42304\tvalidation_1-rmse:1.37046\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.2143\tvalidation_1-rmse:1.0149\n",
      "BEST_ITER: 1999\n",
      "[15:34:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.32911\tvalidation_1-rmse:1.40145\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.14389\tvalidation_1-rmse:1.03087\n",
      "BEST_ITER: 1999\n",
      "[15:34:57] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.39954\tvalidation_1-rmse:1.37833\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:1.1835\tvalidation_1-rmse:1.01997\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of Attribute10 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:35:12] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.42963\tvalidation_1-rmse:1.41973\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.933351\tvalidation_1-rmse:0.749383\n",
      "BEST_ITER: 1999\n",
      "[15:35:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.41516\tvalidation_1-rmse:1.42481\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.922995\tvalidation_1-rmse:0.741122\n",
      "BEST_ITER: 1999\n",
      "[15:35:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.44084\tvalidation_1-rmse:1.41736\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.86592\tvalidation_1-rmse:0.761428\n",
      "BEST_ITER: 1999\n",
      "[15:35:56] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.40577\tvalidation_1-rmse:1.42905\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.854261\tvalidation_1-rmse:0.761641\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of p1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 6)\n",
      "Testing Data Shape:  (6000, 6)\n",
      "[15:36:09] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.22154\tvalidation_1-rmse:1.18795\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.707175\tvalidation_1-rmse:0.594258\n",
      "BEST_ITER: 1999\n",
      "[15:36:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.19713\tvalidation_1-rmse:1.19604\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.693549\tvalidation_1-rmse:0.603687\n",
      "BEST_ITER: 1999\n",
      "[15:36:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.1824\tvalidation_1-rmse:1.20101\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.696044\tvalidation_1-rmse:0.597262\n",
      "BEST_ITER: 1999\n",
      "[15:36:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:1.18412\tvalidation_1-rmse:1.2001\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 300 rounds.\n",
      "[1999]\tvalidation_0-rmse:0.695291\tvalidation_1-rmse:0.596476\n",
      "BEST_ITER: 1999\n",
      "\n",
      "Prediction of p2 is done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('final_data/ctb1_train.csv')\n",
    "test = pd.read_csv('final_data/ctb1_test.csv')\n",
    "# for i in range(4, 7):\n",
    "for y in ['Attribute{0}'.format(i) for i in range(1, 11)] + ['p1', 'p2']:\n",
    "#     feat = ['Parameter{0}'.format(i) for i in range(1, 11)] + ['p1', 'p2']\n",
    "#     y = 'Attribute{0}'.format(i)\n",
    "    X_train = train[para_feat + [y]]\n",
    "    X_test = test[para_feat + ['Group']]\n",
    "\n",
    "    submission, fi, metric, train_sub = model(X_train, X_test, y)\n",
    "    train['xgb1_'+y] = train_sub[y]\n",
    "    test['xgb1_'+y] = submission[y]\n",
    "    print('\\nPrediction of', y, 'is done!\\n')\n",
    "    \n",
    "train.to_csv('final_data/xgb1_train.csv', index=False)\n",
    "test.to_csv('final_data/xgb1_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "      <th>...</th>\n",
       "      <th>xgb1_Attribute3</th>\n",
       "      <th>xgb1_Attribute4</th>\n",
       "      <th>xgb1_Attribute5</th>\n",
       "      <th>xgb1_Attribute6</th>\n",
       "      <th>xgb1_Attribute7</th>\n",
       "      <th>xgb1_Attribute8</th>\n",
       "      <th>xgb1_Attribute9</th>\n",
       "      <th>xgb1_Attribute10</th>\n",
       "      <th>xgb1_p1</th>\n",
       "      <th>xgb1_p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.628417</td>\n",
       "      <td>-0.454090</td>\n",
       "      <td>-0.728591</td>\n",
       "      <td>-1.063207</td>\n",
       "      <td>0.156567</td>\n",
       "      <td>0.090050</td>\n",
       "      <td>-1.414726</td>\n",
       "      <td>0.467028</td>\n",
       "      <td>0.302299</td>\n",
       "      <td>-0.708453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422993</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>0.666180</td>\n",
       "      <td>-0.891161</td>\n",
       "      <td>-0.132688</td>\n",
       "      <td>-0.406348</td>\n",
       "      <td>-0.477419</td>\n",
       "      <td>-0.018344</td>\n",
       "      <td>0.239275</td>\n",
       "      <td>-0.770448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.358538</td>\n",
       "      <td>1.513094</td>\n",
       "      <td>-0.052427</td>\n",
       "      <td>1.472793</td>\n",
       "      <td>-1.561715</td>\n",
       "      <td>-1.773336</td>\n",
       "      <td>-0.221251</td>\n",
       "      <td>-0.927835</td>\n",
       "      <td>2.948223</td>\n",
       "      <td>-0.280689</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.031966</td>\n",
       "      <td>2.025417</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>2.378591</td>\n",
       "      <td>1.176796</td>\n",
       "      <td>1.238690</td>\n",
       "      <td>1.630638</td>\n",
       "      <td>1.528413</td>\n",
       "      <td>1.550742</td>\n",
       "      <td>1.823246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.331766</td>\n",
       "      <td>1.073637</td>\n",
       "      <td>4.900365</td>\n",
       "      <td>4.131766</td>\n",
       "      <td>-1.561715</td>\n",
       "      <td>-1.773336</td>\n",
       "      <td>-0.221251</td>\n",
       "      <td>-0.927835</td>\n",
       "      <td>2.948223</td>\n",
       "      <td>-0.280689</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.031966</td>\n",
       "      <td>2.025417</td>\n",
       "      <td>0.369417</td>\n",
       "      <td>2.378591</td>\n",
       "      <td>1.176796</td>\n",
       "      <td>1.238690</td>\n",
       "      <td>1.630638</td>\n",
       "      <td>1.528413</td>\n",
       "      <td>1.550742</td>\n",
       "      <td>1.823246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.152554</td>\n",
       "      <td>-1.742806</td>\n",
       "      <td>2.501081</td>\n",
       "      <td>1.580783</td>\n",
       "      <td>-0.368463</td>\n",
       "      <td>-0.502846</td>\n",
       "      <td>-1.414726</td>\n",
       "      <td>1.251639</td>\n",
       "      <td>-1.285255</td>\n",
       "      <td>-1.991743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029555</td>\n",
       "      <td>1.052139</td>\n",
       "      <td>1.622052</td>\n",
       "      <td>-0.817889</td>\n",
       "      <td>1.224953</td>\n",
       "      <td>0.825307</td>\n",
       "      <td>0.162978</td>\n",
       "      <td>-0.148923</td>\n",
       "      <td>1.367410</td>\n",
       "      <td>-0.788233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.019031</td>\n",
       "      <td>1.203683</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>1.223124</td>\n",
       "      <td>-0.320733</td>\n",
       "      <td>-0.333447</td>\n",
       "      <td>-1.414726</td>\n",
       "      <td>1.251639</td>\n",
       "      <td>-1.285255</td>\n",
       "      <td>-1.991743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192983</td>\n",
       "      <td>0.965949</td>\n",
       "      <td>1.275539</td>\n",
       "      <td>-0.540761</td>\n",
       "      <td>0.373637</td>\n",
       "      <td>0.410098</td>\n",
       "      <td>0.423164</td>\n",
       "      <td>0.314448</td>\n",
       "      <td>1.169121</td>\n",
       "      <td>-0.546591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "0   -0.628417   -0.454090   -0.728591   -1.063207    0.156567    0.090050   \n",
       "1   -1.358538    1.513094   -0.052427    1.472793   -1.561715   -1.773336   \n",
       "2    1.331766    1.073637    4.900365    4.131766   -1.561715   -1.773336   \n",
       "3   -0.152554   -1.742806    2.501081    1.580783   -0.368463   -0.502846   \n",
       "4    1.019031    1.203683   -0.001719    1.223124   -0.320733   -0.333447   \n",
       "\n",
       "   Parameter7  Parameter8  Parameter9  Parameter10  ...  xgb1_Attribute3  \\\n",
       "0   -1.414726    0.467028    0.302299    -0.708453  ...         0.422993   \n",
       "1   -0.221251   -0.927835    2.948223    -0.280689  ...        -1.031966   \n",
       "2   -0.221251   -0.927835    2.948223    -0.280689  ...        -1.031966   \n",
       "3   -1.414726    1.251639   -1.285255    -1.991743  ...        -0.029555   \n",
       "4   -1.414726    1.251639   -1.285255    -1.991743  ...        -0.192983   \n",
       "\n",
       "   xgb1_Attribute4  xgb1_Attribute5  xgb1_Attribute6  xgb1_Attribute7  \\\n",
       "0         0.009790         0.666180        -0.891161        -0.132688   \n",
       "1         2.025417         0.369417         2.378591         1.176796   \n",
       "2         2.025417         0.369417         2.378591         1.176796   \n",
       "3         1.052139         1.622052        -0.817889         1.224953   \n",
       "4         0.965949         1.275539        -0.540761         0.373637   \n",
       "\n",
       "   xgb1_Attribute8  xgb1_Attribute9  xgb1_Attribute10   xgb1_p1   xgb1_p2  \n",
       "0        -0.406348        -0.477419         -0.018344  0.239275 -0.770448  \n",
       "1         1.238690         1.630638          1.528413  1.550742  1.823246  \n",
       "2         1.238690         1.630638          1.528413  1.550742  1.823246  \n",
       "3         0.825307         0.162978         -0.148923  1.367410 -0.788233  \n",
       "4         0.410098         0.423164          0.314448  1.169121 -0.546591  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_attr_feat = ['xgb_Attribute{0}'.format(i) for i in range(4, 7)]\n",
    "# test[attr_feat + pred_attr_feat].head(20)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************LGB 1****************\n",
    "\n",
    "def model(features, test_features, label, encoding='ohe', n_folds = 4):\n",
    "\n",
    "    test_group = test_features['Group']\n",
    "    \n",
    "    labels = features[label]\n",
    "\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = [label])\n",
    "    test_features = test_features.drop(columns = ['Group'])\n",
    "\n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "\n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "\n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "\n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "\n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "\n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "\n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "\n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "\n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "\n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    train_predictions = np.zeros(features.shape[0])\n",
    "\n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "\n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "\n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "\n",
    "        # Create the model\n",
    "        model = lgb.LGBMRegressor(objective = 'regression',n_estimators=2000,min_child_samples=20,num_leaves=20,\n",
    "                                   learning_rate = 0.005, feature_fraction=0.8,\n",
    "                                   subsample = 0.5, n_jobs = -1, random_state = 50)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'rmse',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 2000, verbose = 4000)\n",
    "\n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        print('BEST_ITER:', best_iteration)\n",
    "\n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "\n",
    "        # Make predictions\n",
    "        test_predictions += model.predict(test_features, num_iteration = best_iteration)/ k_fold.n_splits\n",
    "        train_predictions += model.predict(features, num_iteration = best_iteration)/ k_fold.n_splits\n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold      = model.predict(valid_features, num_iteration = best_iteration)/ k_fold.n_splits\n",
    "\n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['rmse']\n",
    "        train_score = model.best_score_['train']['rmse']\n",
    "\n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "\n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'Group': test_group, label: test_predictions})\n",
    "    train_sub = pd.DataFrame({label: train_predictions})\n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "\n",
    "    # Overall validation score\n",
    "    #valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "\n",
    "    # Add the overall scores to the metrics\n",
    "    #valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    valid_scores.append(np.mean(valid_scores))\n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "\n",
    "    # Dataframe of validation scores\n",
    "    metric = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid':valid_scores})\n",
    "\n",
    "    return submission, feature_importances, metric, train_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.87113\ttrain's l2: 3.50112\tvalid's rmse: 2.15252\tvalid's l2: 4.63333\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.91049\ttrain's l2: 3.64999\tvalid's rmse: 2.02551\tvalid's l2: 4.1027\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.88525\ttrain's l2: 3.55416\tvalid's rmse: 2.1349\tvalid's l2: 4.55781\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.8687\ttrain's l2: 3.49205\tvalid's rmse: 2.15578\tvalid's l2: 4.64739\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.95012\ttrain's l2: 3.80297\tvalid's rmse: 2.13118\tvalid's l2: 4.54195\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.93799\ttrain's l2: 3.7558\tvalid's rmse: 2.17198\tvalid's l2: 4.71749\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.91984\ttrain's l2: 3.68579\tvalid's rmse: 2.22191\tvalid's l2: 4.93688\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.94252\ttrain's l2: 3.77337\tvalid's rmse: 2.16932\tvalid's l2: 4.70595\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute2 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.29141\ttrain's l2: 1.66775\tvalid's rmse: 1.4072\tvalid's l2: 1.9802\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.27221\ttrain's l2: 1.61851\tvalid's rmse: 1.4652\tvalid's l2: 2.1468\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.28772\ttrain's l2: 1.65821\tvalid's rmse: 1.42202\tvalid's l2: 2.02213\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 1.28055\ttrain's l2: 1.63981\tvalid's rmse: 1.44425\tvalid's l2: 2.08586\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute3 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.721745\ttrain's l2: 0.520916\tvalid's rmse: 0.831885\tvalid's l2: 0.692033\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.715971\ttrain's l2: 0.512615\tvalid's rmse: 0.835127\tvalid's l2: 0.697437\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.726516\ttrain's l2: 0.527825\tvalid's rmse: 0.801169\tvalid's l2: 0.641872\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.728452\ttrain's l2: 0.530643\tvalid's rmse: 0.798426\tvalid's l2: 0.637485\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute4 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.636376\ttrain's l2: 0.404974\tvalid's rmse: 0.749484\tvalid's l2: 0.561726\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.631972\ttrain's l2: 0.399388\tvalid's rmse: 0.756304\tvalid's l2: 0.571995\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.643111\ttrain's l2: 0.413591\tvalid's rmse: 0.713475\tvalid's l2: 0.509047\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.651243\ttrain's l2: 0.424118\tvalid's rmse: 0.692339\tvalid's l2: 0.479333\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute5 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.698734\ttrain's l2: 0.48823\tvalid's rmse: 0.796654\tvalid's l2: 0.634657\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.704811\ttrain's l2: 0.496759\tvalid's rmse: 0.7688\tvalid's l2: 0.591054\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.700846\ttrain's l2: 0.491185\tvalid's rmse: 0.780022\tvalid's l2: 0.608434\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.699576\ttrain's l2: 0.489407\tvalid's rmse: 0.789699\tvalid's l2: 0.623624\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute6 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.960308\ttrain's l2: 0.922191\tvalid's rmse: 1.11736\tvalid's l2: 1.24849\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.964184\ttrain's l2: 0.92965\tvalid's rmse: 1.09265\tvalid's l2: 1.19389\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.95852\ttrain's l2: 0.918761\tvalid's rmse: 1.10142\tvalid's l2: 1.21313\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.967683\ttrain's l2: 0.936411\tvalid's rmse: 1.08733\tvalid's l2: 1.1823\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute7 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.948153\ttrain's l2: 0.898993\tvalid's rmse: 1.1095\tvalid's l2: 1.231\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.952731\ttrain's l2: 0.907695\tvalid's rmse: 1.08877\tvalid's l2: 1.18542\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.956564\ttrain's l2: 0.915015\tvalid's rmse: 1.06121\tvalid's l2: 1.12616\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.952293\ttrain's l2: 0.906861\tvalid's rmse: 1.08773\tvalid's l2: 1.18316\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute8 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.934648\ttrain's l2: 0.873568\tvalid's rmse: 1.11366\tvalid's l2: 1.24024\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.95022\ttrain's l2: 0.902918\tvalid's rmse: 1.06368\tvalid's l2: 1.1314\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.954602\ttrain's l2: 0.911264\tvalid's rmse: 1.05042\tvalid's l2: 1.10337\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.94606\ttrain's l2: 0.895029\tvalid's rmse: 1.07082\tvalid's l2: 1.14666\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute9 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.942625\ttrain's l2: 0.888542\tvalid's rmse: 1.11534\tvalid's l2: 1.24398\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.959949\ttrain's l2: 0.921502\tvalid's rmse: 1.0988\tvalid's l2: 1.20735\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.971626\ttrain's l2: 0.944058\tvalid's rmse: 1.02485\tvalid's l2: 1.05031\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.9614\ttrain's l2: 0.924291\tvalid's rmse: 1.08516\tvalid's l2: 1.17757\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of Attribute10 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.702432\ttrain's l2: 0.493411\tvalid's rmse: 0.819614\tvalid's l2: 0.671767\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.694217\ttrain's l2: 0.481937\tvalid's rmse: 0.825373\tvalid's l2: 0.681241\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.711047\ttrain's l2: 0.505587\tvalid's rmse: 0.776263\tvalid's l2: 0.602584\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.711073\ttrain's l2: 0.505625\tvalid's rmse: 0.768147\tvalid's l2: 0.59005\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of p1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.560527\ttrain's l2: 0.31419\tvalid's rmse: 0.638848\tvalid's l2: 0.408127\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.566006\ttrain's l2: 0.320363\tvalid's rmse: 0.61358\tvalid's l2: 0.376481\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.561191\ttrain's l2: 0.314935\tvalid's rmse: 0.631545\tvalid's l2: 0.398849\n",
      "BEST_ITER: 2000\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's rmse: 0.560841\ttrain's l2: 0.314542\tvalid's rmse: 0.630869\tvalid's l2: 0.397995\n",
      "BEST_ITER: 2000\n",
      "\n",
      "Prediction of p2 is done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('final_data/xgb1_train.csv')\n",
    "test = pd.read_csv('final_data/xgb1_test.csv')\n",
    "\n",
    "# for i in range(4, 7):\n",
    "for y in ['Attribute{0}'.format(i) for i in range(1, 11)] + ['p1', 'p2']:\n",
    "    new_feat = ['xgb1_'+y]\n",
    "    X_train = train[para_feat + new_feat + [y]]\n",
    "    X_test = test[para_feat + new_feat + ['Group']]\n",
    "\n",
    "    submission, fi, metric, train_sub = model(X_train, X_test, y)\n",
    "    train['lgb1_'+y] = train_sub[y]\n",
    "    test['lgb1_'+y] = submission[y]\n",
    "    print('\\nPrediction of', y, 'is done!\\n')\n",
    "    \n",
    "train.to_csv('final_data/lgb1_train.csv', index=False)\n",
    "test.to_csv('final_data/lgb1_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_attr_feat = ['lgb_Attribute{0}'.format(i) for i in range(4, 7)]\n",
    "# test[attr_feat + pred_attr_feat].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************LGB 2*****************\n",
    "\n",
    "def model(features, test_features, label, encoding='ohe', n_folds = 4):\n",
    "\n",
    "    test_group = test_features['Group']\n",
    "    \n",
    "    labels = features[label]\n",
    "\n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = [label])\n",
    "    test_features = test_features.drop(columns = ['Group'])\n",
    "\n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "\n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "\n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "\n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "\n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "\n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "\n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "\n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "\n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "\n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "\n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "\n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "\n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    train_predictions = np.zeros(features.shape[0])\n",
    "\n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "\n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "\n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "\n",
    "        # Create the model\n",
    "        model = lgb.LGBMRegressor(objective = 'regression',n_estimators=5000,min_child_samples=20,num_leaves=26,\n",
    "                                   learning_rate = 0.005, feature_fraction=0.6,\n",
    "                                   subsample = 0.4, n_jobs = -1, random_state = 50)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'rmse',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 2000, verbose = 4000)\n",
    "\n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        print('BEST_ITER:', best_iteration)\n",
    "\n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "\n",
    "        # Make predictions\n",
    "        test_predictions += model.predict(test_features, num_iteration = best_iteration)/ k_fold.n_splits\n",
    "        train_predictions += model.predict(features, num_iteration = best_iteration)/ k_fold.n_splits\n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold      = model.predict(valid_features, num_iteration = best_iteration)/ k_fold.n_splits\n",
    "\n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['rmse']\n",
    "        train_score = model.best_score_['train']['rmse']\n",
    "\n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "\n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'Group': test_group, label: test_predictions})\n",
    "    train_sub = pd.DataFrame({label: train_predictions})\n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "\n",
    "    # Overall validation score\n",
    "    #valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "\n",
    "    # Add the overall scores to the metrics\n",
    "    #valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    valid_scores.append(np.mean(valid_scores))\n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "\n",
    "    # Dataframe of validation scores\n",
    "    metric = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid':valid_scores})\n",
    "\n",
    "    return submission, feature_importances, metric, train_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttrain's rmse: 1.87662\ttrain's l2: 3.5217\tvalid's rmse: 2.02625\tvalid's l2: 4.10571\n",
      "BEST_ITER: 520\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttrain's rmse: 1.91004\ttrain's l2: 3.64824\tvalid's rmse: 1.90542\tvalid's l2: 3.63063\n",
      "BEST_ITER: 552\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 1.87795\ttrain's l2: 3.52668\tvalid's rmse: 1.99605\tvalid's l2: 3.98422\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[524]\ttrain's rmse: 1.87596\ttrain's l2: 3.51924\tvalid's rmse: 2.01476\tvalid's l2: 4.05925\n",
      "BEST_ITER: 524\n",
      "\n",
      "Prediction of Attribute1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttrain's rmse: 1.95941\ttrain's l2: 3.83928\tvalid's rmse: 2.00181\tvalid's l2: 4.00724\n",
      "BEST_ITER: 520\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttrain's rmse: 1.94375\ttrain's l2: 3.77814\tvalid's rmse: 2.04064\tvalid's l2: 4.16423\n",
      "BEST_ITER: 520\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttrain's rmse: 1.9278\ttrain's l2: 3.71643\tvalid's rmse: 2.09226\tvalid's l2: 4.37755\n",
      "BEST_ITER: 520\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttrain's rmse: 1.94539\ttrain's l2: 3.78452\tvalid's rmse: 2.03534\tvalid's l2: 4.1426\n",
      "BEST_ITER: 562\n",
      "\n",
      "Prediction of Attribute2 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 1.28626\ttrain's l2: 1.65448\tvalid's rmse: 1.32218\tvalid's l2: 1.74817\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[537]\ttrain's rmse: 1.27528\ttrain's l2: 1.62635\tvalid's rmse: 1.37921\tvalid's l2: 1.90221\n",
      "BEST_ITER: 537\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 1.28203\ttrain's l2: 1.64361\tvalid's rmse: 1.33447\tvalid's l2: 1.78082\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttrain's rmse: 1.28412\ttrain's l2: 1.64898\tvalid's rmse: 1.35294\tvalid's l2: 1.83045\n",
      "BEST_ITER: 520\n",
      "\n",
      "Prediction of Attribute3 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[925]\ttrain's rmse: 0.716518\ttrain's l2: 0.513398\tvalid's rmse: 0.795411\tvalid's l2: 0.632679\n",
      "BEST_ITER: 925\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[985]\ttrain's rmse: 0.712655\ttrain's l2: 0.507877\tvalid's rmse: 0.800235\tvalid's l2: 0.640377\n",
      "BEST_ITER: 985\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[844]\ttrain's rmse: 0.724991\ttrain's l2: 0.525612\tvalid's rmse: 0.773133\tvalid's l2: 0.597734\n",
      "BEST_ITER: 844\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttrain's rmse: 0.728043\ttrain's l2: 0.530047\tvalid's rmse: 0.756613\tvalid's l2: 0.572463\n",
      "BEST_ITER: 861\n",
      "\n",
      "Prediction of Attribute4 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[860]\ttrain's rmse: 0.639572\ttrain's l2: 0.409052\tvalid's rmse: 0.714328\tvalid's l2: 0.510264\n",
      "BEST_ITER: 860\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[933]\ttrain's rmse: 0.633702\ttrain's l2: 0.401578\tvalid's rmse: 0.722979\tvalid's l2: 0.522698\n",
      "BEST_ITER: 933\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1102]\ttrain's rmse: 0.63712\ttrain's l2: 0.405921\tvalid's rmse: 0.684936\tvalid's l2: 0.469137\n",
      "BEST_ITER: 1102\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttrain's rmse: 0.654926\ttrain's l2: 0.428929\tvalid's rmse: 0.664141\tvalid's l2: 0.441084\n",
      "BEST_ITER: 861\n",
      "\n",
      "Prediction of Attribute5 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[818]\ttrain's rmse: 0.696629\ttrain's l2: 0.485292\tvalid's rmse: 0.762247\tvalid's l2: 0.58102\n",
      "BEST_ITER: 818\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[914]\ttrain's rmse: 0.698571\ttrain's l2: 0.488001\tvalid's rmse: 0.741893\tvalid's l2: 0.550405\n",
      "BEST_ITER: 914\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[939]\ttrain's rmse: 0.696533\ttrain's l2: 0.485158\tvalid's rmse: 0.747614\tvalid's l2: 0.558927\n",
      "BEST_ITER: 939\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[939]\ttrain's rmse: 0.693914\ttrain's l2: 0.481517\tvalid's rmse: 0.75423\tvalid's l2: 0.568863\n",
      "BEST_ITER: 939\n",
      "\n",
      "Prediction of Attribute6 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttrain's rmse: 0.949301\ttrain's l2: 0.901173\tvalid's rmse: 1.0467\tvalid's l2: 1.09558\n",
      "BEST_ITER: 845\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[657]\ttrain's rmse: 0.963094\ttrain's l2: 0.92755\tvalid's rmse: 1.02403\tvalid's l2: 1.04864\n",
      "BEST_ITER: 657\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 0.961828\ttrain's l2: 0.925112\tvalid's rmse: 1.03574\tvalid's l2: 1.07276\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 0.970108\ttrain's l2: 0.941109\tvalid's rmse: 1.01405\tvalid's l2: 1.02829\n",
      "BEST_ITER: 616\n",
      "\n",
      "Prediction of Attribute7 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttrain's rmse: 0.952162\ttrain's l2: 0.906612\tvalid's rmse: 1.03709\tvalid's l2: 1.07556\n",
      "BEST_ITER: 661\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttrain's rmse: 0.943744\ttrain's l2: 0.890653\tvalid's rmse: 1.01943\tvalid's l2: 1.03924\n",
      "BEST_ITER: 845\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 0.961744\ttrain's l2: 0.924951\tvalid's rmse: 0.999399\tvalid's l2: 0.998798\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[628]\ttrain's rmse: 0.955649\ttrain's l2: 0.913264\tvalid's rmse: 1.0308\tvalid's l2: 1.06256\n",
      "BEST_ITER: 628\n",
      "\n",
      "Prediction of Attribute8 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttrain's rmse: 0.927278\ttrain's l2: 0.859845\tvalid's rmse: 1.04516\tvalid's l2: 1.09236\n",
      "BEST_ITER: 856\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 0.952259\ttrain's l2: 0.906798\tvalid's rmse: 1.00051\tvalid's l2: 1.00103\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[845]\ttrain's rmse: 0.945409\ttrain's l2: 0.893798\tvalid's rmse: 0.991388\tvalid's l2: 0.982849\n",
      "BEST_ITER: 845\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttrain's rmse: 0.957155\ttrain's l2: 0.916145\tvalid's rmse: 1.01174\tvalid's l2: 1.02361\n",
      "BEST_ITER: 562\n",
      "\n",
      "Prediction of Attribute9 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 0.951971\ttrain's l2: 0.906249\tvalid's rmse: 1.05947\tvalid's l2: 1.12247\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[628]\ttrain's rmse: 0.964504\ttrain's l2: 0.930268\tvalid's rmse: 1.04541\tvalid's l2: 1.09289\n",
      "BEST_ITER: 628\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 0.976638\ttrain's l2: 0.953822\tvalid's rmse: 0.977565\tvalid's l2: 0.955634\n",
      "BEST_ITER: 616\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttrain's rmse: 0.967009\ttrain's l2: 0.935106\tvalid's rmse: 1.02909\tvalid's l2: 1.05903\n",
      "BEST_ITER: 616\n",
      "\n",
      "Prediction of Attribute10 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[860]\ttrain's rmse: 0.700203\ttrain's l2: 0.490284\tvalid's rmse: 0.780115\tvalid's l2: 0.608579\n",
      "BEST_ITER: 860\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1021]\ttrain's rmse: 0.690366\ttrain's l2: 0.476605\tvalid's rmse: 0.790706\tvalid's l2: 0.625216\n",
      "BEST_ITER: 1021\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[985]\ttrain's rmse: 0.703763\ttrain's l2: 0.495283\tvalid's rmse: 0.7409\tvalid's l2: 0.548932\n",
      "BEST_ITER: 985\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[861]\ttrain's rmse: 0.709995\ttrain's l2: 0.504093\tvalid's rmse: 0.738517\tvalid's l2: 0.545407\n",
      "BEST_ITER: 861\n",
      "\n",
      "Prediction of p1 is done!\n",
      "\n",
      "Training Data Shape:  (6000, 7)\n",
      "Testing Data Shape:  (6000, 7)\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttrain's rmse: 0.556255\ttrain's l2: 0.309419\tvalid's rmse: 0.607248\tvalid's l2: 0.36875\n",
      "BEST_ITER: 856\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[985]\ttrain's rmse: 0.556924\ttrain's l2: 0.310164\tvalid's rmse: 0.591651\tvalid's l2: 0.350051\n",
      "BEST_ITER: 985\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[925]\ttrain's rmse: 0.55717\ttrain's l2: 0.310438\tvalid's rmse: 0.598035\tvalid's l2: 0.357646\n",
      "BEST_ITER: 925\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttrain's rmse: 0.553351\ttrain's l2: 0.306197\tvalid's rmse: 0.605801\tvalid's l2: 0.366995\n",
      "BEST_ITER: 983\n",
      "\n",
      "Prediction of p2 is done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('final_data/lgb1_train.csv')\n",
    "test = pd.read_csv('final_data/lgb1_test.csv')\n",
    "\n",
    "# for i in range(4, 7):\n",
    "for y in ['Attribute{0}'.format(i) for i in range(1, 11)] + ['p1', 'p2']:\n",
    "    new_feat = ['lgb1_'+y]\n",
    "    X_train = train[para_feat + new_feat + [y]]\n",
    "    X_test = test[para_feat + new_feat + ['Group']]\n",
    "\n",
    "    submission, fi, metric, train_sub = model(X_train, X_test, y)\n",
    "    train['lgb2_'+y] = train_sub[y]\n",
    "    test['lgb2_'+y] = submission[y]\n",
    "    print('\\nPrediction of', y, 'is done!\\n')\n",
    "    \n",
    "train.to_csv('final_data/lgb2_train.csv', index=False)\n",
    "test.to_csv('final_data/lgb2_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
